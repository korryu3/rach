# Databricks notebook source
# MAGIC %pip install -U -qqqq databricks-agents mlflow mlflow-skinny databricks-vectorsearch langchain==0.2.11 langchain_core==0.2.23 langchain_community==0.2.10 openai

# COMMAND ----------

# MAGIC %restart_python

# COMMAND ----------

# MAGIC %run ./config

# COMMAND ----------

import yaml
import mlflow

rag_chain_config = {
      "vector_search_endpoint_name": VECTOR_SEARCH_ENDPOINT_NAME,
      "source_table_name": f"{catalog}.{dbName}.{embed_table_name}",
      "vector_search_index_name": f"{catalog}.{dbName}.{embed_table_name}_vs_index",
      "llm_endpoint_name": instruct_endpoint_name,
}

config_file_name = 'rag_chain_config.yaml'
try:
    with open(config_file_name, 'w') as f:
        yaml.dump(rag_chain_config, f)
except:
    print('pass to work on build job')

# COMMAND ----------

import os

# Specify the full path to the chain notebook
chain_notebook_path = os.path.join(os.getcwd(), "chain_langchain")

# Specify the full path to the config file (.yaml)
config_file_path = os.path.join(os.getcwd(), "rag_chain_config.yaml")

print(f"Chain notebook path: {chain_notebook_path}")
print(f"Chain notebook path: {config_file_path}")

# COMMAND ----------

user_account_name = dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()

# COMMAND ----------

import mlflow

mlflow.set_registry_uri("databricks-uc")

# Set the experiment name
mlflow.set_experiment(f"/Users/{user_account_name}/rach_rag_experiment")

model_name = f"{catalog}.{dbName}.{registered_model_name}"

# Log the model to MLflow
# TODO: remove example_no_conversion once this papercut is fixed
with mlflow.start_run(run_name="rach_rag_chatbot"):
    # Tag to differentiate from the data pipeline runs
    mlflow.set_tag("type", "chain")

    input_example = {
        "messages": [{"role": "user", "content": "æŽˆæ¥­æ™‚é–“ã¯ä¸€ã‚³ãƒžã©ã®ãã‚‰ã„ã§ã™ã‹ï¼Ÿ"}]
    }

    logged_chain_info = mlflow.langchain.log_model(
        lc_model=chain_notebook_path,  # Chain code file e.g., /path/to/the/chain.py
        model_config=config_file_path,  # Chain configuration set in 00_config
        artifact_path="chain",  # Required by MLflow
        input_example=input_example,  # Save the chain's input schema.  MLflow will execute the chain before logging & capture it's output schema.
        example_no_conversion=True,  # Required by MLflow to use the input_example as the chain's schema
        registered_model_name=model_name,
    )

# COMMAND ----------

chain = mlflow.langchain.load_model(logged_chain_info.model_uri)

# COMMAND ----------

import mlflow

mlflow.set_registry_uri("databricks-uc")

model_name = f"{catalog}.{dbName}.{registered_model_name}"
uc_model_info = mlflow.register_model(model_uri=logged_chain_info.model_uri, name=model_name)

# COMMAND ----------

### Test the registered model
registered_agent = mlflow.langchain.load_model(f"models:/{model_name}/{uc_model_info.version}")

registered_agent.invoke(input_example)

# COMMAND ----------

# Deploy

import os
import mlflow
from databricks import agents

# modelã‚’deployã™ã‚‹
deployment_info = agents.deploy(
    model_name, 
    uc_model_info.version 
)

browser_url = mlflow.utils.databricks_utils.get_browser_hostname()
print(f"\n\nView deployment status: https://{browser_url}/ml/endpoints/{deployment_info.endpoint_name}")

review_instructions = """### Rach FAQãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ†ã‚¹ãƒˆæ‰‹é †

ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®å“è³ªå‘ä¸Šã®ãŸã‚ã«ãœã²ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ãã ã•ã„ã€‚

1. **å¤šæ§˜ãªè³ªå•ã‚’ãŠè©¦ã—ãã ã•ã„**ï¼š
   - å®Ÿéš›ã®ãŠå®¢æ§˜ãŒå°‹ã­ã‚‹ã¨äºˆæƒ³ã•ã‚Œã‚‹å¤šæ§˜ãªè³ªå•ã‚’å…¥åŠ›ãã ã•ã„ã€‚ã“ã‚Œã¯ã€äºˆæƒ³ã•ã‚Œã‚‹è³ªå•ã‚’åŠ¹æžœçš„ã«å‡¦ç†ã§ãã‚‹ã‹å¦ã‹ã‚’ç¢ºèªã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚

2. **å›žç­”ã«å¯¾ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯**ï¼š
   - è³ªå•ã®å¾Œã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚’ä½¿ã£ã¦ã€ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®å›žç­”ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
   - å›žç­”ãŒé–“é•ã£ã¦ã„ãŸã‚Šã€æ”¹å–„ã™ã¹ãç‚¹ãŒã‚ã‚‹å ´åˆã¯ã€ã€Œå›žç­”ã®ç·¨é›†ï¼ˆEdit Responseï¼‰ã€ã§ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚çš†æ§˜ã®ä¿®æ­£ã«ã‚ˆã‚Šã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ç²¾åº¦ã‚’å‘ä¸Šã§ãã¾ã™ã€‚

3. **å›žç­”ã«ä»˜éšã—ã¦ã„ã‚‹å‚è€ƒæ–‡çŒ®ã®ç¢ºèª**ï¼š
   - è³ªå•ã«å¯¾ã—ã¦ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰å›žç­”ã•ã‚Œã‚‹å„å‚è€ƒæ–‡çŒ®ã‚’ã”ç¢ºèªãã ã•ã„ã€‚
   - GoodðŸ‘ï¼BadðŸ‘Žæ©Ÿèƒ½ã‚’ä½¿ã£ã¦ã€ãã®æ–‡æ›¸ãŒè³ªå•å†…å®¹ã«é–¢é€£ã—ã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’è©•ä¾¡ãã ã•ã„ã€‚

ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®è©•ä¾¡ã«ãŠæ™‚é–“ã‚’å‰²ã„ã¦ã„ãŸã ãã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é«˜å“è³ªã®è£½å“ã‚’ãŠå±Šã‘ã™ã‚‹ãŸã‚ã«ã¯ã€çš†æ§˜ã®ã”å”åŠ›ãŒä¸å¯æ¬ ã§ã™ã€‚"""

agents.set_review_instructions(model_name, review_instructions)

# COMMAND ----------

import time
from databricks.sdk import WorkspaceClient
from databricks.sdk.service.serving import EndpointStateReady, EndpointStateConfigUpdate
from databricks.sdk.errors import NotFound, ResourceDoesNotExist

# Wait for the Review App to be ready
print("\nWaiting for endpoint to deploy.  This can take 15 - 20 minutes.", end="")
w = WorkspaceClient()
now = time.time()
while w.serving_endpoints.get(deployment_info.endpoint_name).state.ready == EndpointStateReady.NOT_READY or w.serving_endpoints.get(deployment_info.endpoint_name).state.config_update == EndpointStateConfigUpdate.IN_PROGRESS:
    print(".", end="")
    time.sleep(30)

    if time.time() - now > 3600:
        raise Exception("Endpoint did not deploy in 1 hour")

print(f"\n\nReview App: {deployment_info.review_app_url}")

# COMMAND ----------

from databricks import agents

user_list = ["ttc2350sa0009@edu.tech.ac.jp"]
agents.set_permissions(model_name=model_name, users=user_list, permission_level=agents.PermissionLevel.CAN_QUERY)

print(f"Share this URL with your stakeholders: {deployment_info.review_app_url}")

# COMMAND ----------


